During this section the final setup of the robot will be reviewed. Firstly, the differences between the initial and the final robot setup will be explained, in terms of hardware, and second the results obtained with it, trying to discuss a bit the reason of them.

\subsection{Innovations in setup}

Mainly, the innovations on hardware can be divided in two different parts, the ones that are helping the \textit{vision module}, and the ones that are providing feedback or interaction with the children. The first group includes the new near-IR camera and the IR LED. The second group contains the button and the speaker.

The aim of the first group is to boost the performance of the \textit{vision module}. It is focused in the use of IR lighting, with the addition of IR LED and the replacement of the regular camera by a near-IR one. Also the position of the camera has been changed in order to increase the \textit{field of view}.

The second group, as said above, tries to improve the experience of the children by adding interaction. The button will allow to start and stop the program when needed. Even if it is quite simple, it becomes important to do such action so that the robot does not need to be connected to the computer in order to initialize the program again. The speaker will provide sound feedback. For example, in the case of the button pressed, it will play a short sound so the children know when the robot has started the program or closed it.


\subsection{Results and discussion}

In this subsection the results obtained during the different tests will be presented. A comparison with old and new methods will be reviewed in order to see the improvements done and the performance of the current program. 

One of the first things that was implemented in the \textit{vision module} was the angle detection of the arrow. As it has been explained in previous sections, initially, detection was using the centre of mass of the contour and the centre of the rectangle in order to get the angle. This method had a lot of errors and it was producing a deviation of $\pm 20º$ according to the real value. Also the angle computed was changing very fast in this range and it was difficult to obtain a clear measure. In order to improve that, a new method was designed, which fits a line along the arrow. This solution is really easy to implement and the results show that the deviation is only $\pm 3º$ with respect to the real value. With this little improvement, the performance of the angle detection was increased, thus the turns of the robot are much precise with the direction pointed by the arrow. Figure \ref{fig:angle} represents this improvement in a visual way.

\begin{figure}[h]
\centering
\begin{tikzpicture}
  \begin{axis}[
        xtick={},
        xticklabels={},
        ytick={},
        yticklabels={},
        axis lines = middle,
        ymin=-3, ymax=3,
        xmin=2, xmax=4,
      axis equal]
      
      \addplot[black,sharp plot,update limits=false, ->] 
      			coordinates {(0,0) (4,2)}
      			node[above] at (axis cs:2.7,0.3) {$+20º$}
				node[above] at (axis cs:2.7,-0.8) {$-20º$};
      	
      \addplot[black,sharp plot,update limits=false, ->] 
        		coordinates {(0,0) (4,-2)};

        
      \draw (axis cs:2,-1)arc[radius=2cm,start angle=-30,end angle=27];

    \end{axis}
\end{tikzpicture}
\begin{tikzpicture}
  \begin{axis}[
        xtick={},
        xticklabels={},
        ytick={},
        yticklabels={},
        axis lines = middle,
        axis line style={->},
        ymin=-3, ymax=3,
        xmin=2, xmax=4,
      axis equal]
      
      \addplot[black,sharp plot,update limits=false, ->] 
      			coordinates {(0,0) (4,0.5)}
      			node[above] at (axis cs:2.7,0.3) {$+3º$}
				node[above] at (axis cs:2.7,-0.9) {$-3º$};
      	
      \addplot[black,sharp plot,update limits=false, ->] 
        		coordinates {(0,0) (4,-0.5)};

        
      \draw (axis cs:2,-0.25)arc[radius=2cm,start angle=-8,end angle=5.8];

    \end{axis}
\end{tikzpicture}
\caption{Comparison between the two methods studied for computing the angle of the arrow. On the left side, the old method is giving $\pm 20º$ while the new method reduces substantially the error.}
\label{fig:angle}
\end{figure}

One of the biggest problems is the classification of the signs. This is probably one of the points that should be improved in future work. In the current setting the robot is able to distinguish easily between the cross and the circle because of the \textit{fill ratio}. However, the arrow is more difficult to detect leading up to a $~20\%$ of \textit{false negatives}. This means that every five times an arrow is shown to the robot, one is classified as another sign. This result may vary depending on the lighting conditions although the IR signals may avoid loosing precision in low light conditions. The lack of accuracy of the centre of mass and centre of rectangle method is leading to these \textit{false negatives} because sometimes these two points are not split enough and the sign is not classified as an arrow. Probably, getting some information about the shape of the bounding box would help in order to improve the arrow detection.

It has been also detected that when the arrow is placed pointing near $90º$ either left or right, the detections are much more better than when the arrow is pointing forward with respect to the current angle of the robot. This is probably caused by the perspective of the camera with respect to the ground plane. Whenever the arrow is pointing forward the deformation due to the perspective is causing the centre of mass to be very close to the centre of the bounding box. More stylized arrows would probably solve the problem by shifting a bit the centre of mass towards the direction of the arrow. In this case, it would be difficult to use the shape of the bounding box since an arrow in perspective is seen frequently as a square.

As seen in table \ref{tab:cam_perf}, the RPi camera is able to give up to 18 frames per second \textit{(fps)}. However, this performance speed is not reached due to the high demand of computational resources required by the \textit{vision} module. The tests during most of the code development process were always performed using \textit{graphical user interface} on the Raspberry Pi and showing results using an external display. It was the unique way to check if everything was running perfectly on the RPi since all the code was developed on \textit{Visual Studio} under \textit{Windows}. The processing speed achieved with this configuration were very close to 5 \textit{fps}, in an image of $160\times120$. However, the final version of the program does not need to show anything on screen. It allows to avoid the execution of all the lines in the code that refers to the \textit{GUI}, mainly showing images and plotting lines, rectangles, proximity areas, etc..

